.. !split

.. _ch:wave:

Wave equations          (1)
%%%%%%%%%%%%%%%%%%%%%%%%%%%

A very wide range of physical processes lead to wave motion, where
signals are propagated through a medium in space and time, normally
with little or no permanent movement of the medium itself.
The shape of the signals may undergo changes as they travel through
matter, but usually not so much that the signals cannot be recognized
at some later point in space and time.
Many types of wave motion can be described by the equation
:math:`u_{tt}=\nabla\cdot (c^2\nabla u) + f`, which we will solve
in the forthcoming text by finite difference methods.

.. _wave:string:

Simulation of waves on a string
===============================

.. index::
   single: waves; on a string

.. index::
   single: wave equation; 1D

We begin our study of wave equations by simulating one-dimensional
waves on a string, say on a guitar or violin.
Let the string in the deformed state
coincide with the interval
:math:`[0,L]` on the :math:`x` axis, and let :math:`u(x,t)` be the displacement at
time :math:`t` in the :math:`y` direction of a point initially at :math:`x`.
The displacement function :math:`u` is governed by the mathematical model

.. _Eq:wave:pde1:

.. math::

    \tag{160}
    \frac{\partial^2 u}{\partial t^2} =
        c^2 \frac{\partial^2 u}{\partial x^2}, \quad x\in (0,L),\ t\in (0,T]
        
        

.. _Eq:wave:pde1:ic:u:

.. math::

    \tag{161}
    u(x,0) = I(x), \quad x\in [0,L]
        
        

.. _Eq:wave:pde1:ic:ut:

.. math::

    \tag{162}
    \frac{\partial}{\partial t}u(x,0) = 0, \quad x\in [0,L]
        
        

.. _Eq:wave:pde1:bc:0:

.. math::

    \tag{163}
    u(0,t)  = 0, \quad  t\in (0,T]
        
        

.. _Eq:wave:pde1:bc:L:

.. math::

    \tag{164}
    u(L,t)  = 0, \quad  t\in (0,T]
        
        

The constant :math:`c` and the function :math:`I(x)` must be prescribed.

Equation :ref:`(160) <Eq:wave:pde1>` is known as the one-dimensional
*wave equation*. Since this PDE contains a second-order derivative
in time, we need *two initial conditions*. The condition
:ref:`(161) <Eq:wave:pde1:ic:u>` specifies
the initial shape of the string, :math:`I(x)`, and
:ref:`(162) <Eq:wave:pde1:ic:ut>` expresses that the initial velocity of the
string is zero. In addition, PDEs need *boundary conditions*, given here as
:ref:`(163) <Eq:wave:pde1:bc:0>` and :ref:`(164) <Eq:wave:pde1:bc:L>`. These two
conditions specify that
the string is fixed at the ends, i.e., that the displacement :math:`u` is zero.

The solution :math:`u(x,t)` varies in space and time and describes waves that
move with velocity :math:`c` to the left and right.

.. raw:: html
        
        <div>
        <video  loop controls width='640' height='365' preload='none'>
            <source src='mov-wave/guitar_C0.8/movie.webm' type='video/webm; codecs="vp8, vorbis"'>
            <source src='mov-wave/guitar_C0.8/movie.ogg'  type='video/ogg;  codecs="theora, vorbis"'>
        </video>
        </div>
        <p><em>Example of waves on a string.</em></p>
        
        <!-- Issue warning if in a Safari browser -->
        <script language="javascript">
        if (!!(window.safari)) {
          document.write("<div style=\"width: 95%%; padding: 10px; border: 1px solid #100; border-radius: 4px;\"><p><font color=\"red\">The above movie will not play in Safari - use Chrome, Firefox, or Opera.</font></p></div>")}
        </script>
        

Sometimes we will use a more compact notation for the partial derivatives
to save space:

.. _Eq:_auto59:

.. math::

    \tag{165}
    u_t = \frac{\partial u}{\partial t}, \quad
        u_{tt} = \frac{\partial^2 u}{\partial t^2},
        
        

and similar expressions
for derivatives with respect to other variables. Then the
wave equation can be written compactly as :math:`u_{tt} = c^2u_{xx}`.

.. index::
   single: wave equation; 1D, finite difference method

The PDE problem :ref:`(160) <Eq:wave:pde1>`-:ref:`(164) <Eq:wave:pde1:bc:L>` will now be
discretized in space and time by a finite difference method.

.. index::
   single: mesh; finite differences

.. _wave:string:mesh:

Discretizing the domain
-----------------------

The temporal domain :math:`[0,T]` is represented by a finite number of mesh points

.. _Eq:_auto60:

.. math::

    \tag{166}
    0 = t_0 < t_1 < t_2 < \cdots < t_{N_t-1} < t_{N_t} = T {\thinspace .}   
        

Similarly, the spatial domain :math:`[0,L]` is replaced by a set of mesh points

.. _Eq:_auto61:

.. math::

    \tag{167}
    0 = x_0 < x_1 < x_2 < \cdots < x_{N_x-1} < x_{N_x} = L {\thinspace .}   
        

One may view the mesh as two-dimensional in the :math:`x,t` plane, consisting
of points :math:`(x_i, t_n)`, with :math:`i=0,\ldots,N_x` and :math:`n=0,\ldots,N_t`.

Uniform meshes
~~~~~~~~~~~~~~

For uniformly distributed mesh points we can introduce the constant
mesh spacings :math:`\Delta t` and :math:`\Delta x`. We have that

.. _Eq:_auto62:

.. math::

    \tag{168}
    x_i = i\Delta x,\ i=0,\ldots,N_x,\quad
        t_n = n\Delta t,\ n=0,\ldots,N_t{\thinspace .}
        
        

We also have that :math:`\Delta x = x_i-x_{i-1}`, :math:`i=1,\ldots,N_x`, and
:math:`\Delta t = t_n - t_{n-1}`, :math:`n=1,\ldots,N_t`. Figure :ref:`wave:pde1:fig:mesh`
displays a mesh in the :math:`x,t` plane with :math:`N_t=5`, :math:`N_x=5`, and constant
mesh spacings.

.. _wave:string:numerical:sol:

The discrete solution
---------------------

.. index::
   single: stencil; 1D wave equation

.. index:: mesh function

The solution :math:`u(x,t)` is sought at the mesh points. We introduce
the mesh function :math:`u_i^n`, which approximates the exact
solution at the
mesh point :math:`(x_i,t_n)` for :math:`i=0,\ldots,N_x` and :math:`n=0,\ldots,N_t`.
Using the finite difference method, we shall
develop algebraic equations for computing the mesh function.

.. _wave:string:samplingPDE:

Fulfilling the equation at the mesh points
------------------------------------------

In the finite difference method, we relax
the condition that :ref:`(160) <Eq:wave:pde1>` holds at all points in
the space-time domain :math:`(0,L)\times (0,T]` to the requirement that the PDE is
fulfilled at the *interior* mesh points only:

.. _Eq:wave:pde1:step2:

.. math::

    \tag{169}
    \frac{\partial^2}{\partial t^2} u(x_i, t_n) =
        c^2\frac{\partial^2}{\partial x^2} u(x_i, t_n),
        
        

for :math:`i=1,\ldots,N_x-1` and :math:`n=1,\ldots,N_t-1`. For :math:`n=0` we have
the initial conditions :math:`u=I(x)` and :math:`u_t=0`,
and at the boundaries :math:`i=0,N_x` we
have the boundary condition :math:`u=0`.

.. _wave:string:fd:

Replacing derivatives by finite differences
-------------------------------------------

The second-order derivatives can be replaced by central
differences. The most widely used difference approximation of
the second-order derivative is

.. math::
         \frac{\partial^2}{\partial t^2}u(x_i,t_n)\approx
        \frac{u_i^{n+1} - 2u_i^n + u^{n-1}_i}{\Delta t^2}{\thinspace .}

It is convenient to introduce the finite difference operator notation

.. math::
         [D_tD_t u]^n_i = \frac{u_i^{n+1} - 2u_i^n + u^{n-1}_i}{\Delta t^2}{\thinspace .}

A similar approximation of the second-order derivative in the :math:`x`
direction reads

.. math::
         \frac{\partial^2}{\partial x^2}u(x_i,t_n)\approx
        \frac{u_{i+1}^{n} - 2u_i^n + u^{n}_{i-1}}{\Delta x^2} = [D_xD_x u]^n_i
        {\thinspace .}
        

Algebraic version of the PDE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We can now replace the derivatives in :ref:`(169) <Eq:wave:pde1:step2>`
and get

.. _Eq:wave:pde1:step3b:

.. math::

    \tag{170}
    \frac{u_i^{n+1} - 2u_i^n + u^{n-1}_i}{\Delta t^2} =
        c^2\frac{u_{i+1}^{n} - 2u_i^n + u^{n}_{i-1}}{\Delta x^2},
        
        

or written more compactly using the operator notation:

.. _Eq:wave:pde1:step3a:

.. math::

    \tag{171}
    [D_tD_t u = c^2 D_xD_x]^{n}_i
        {\thinspace .}
        
        

Interpretation of the equation as a stencil
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A characteristic feature of :ref:`(170) <Eq:wave:pde1:step3b>` is that it
involves :math:`u` values from neighboring points only: :math:`u_i^{n+1}`,
:math:`u^n_{i\pm 1}`, :math:`u^n_i`, and :math:`u^{n-1}_i`.  The circles in Figure
:ref:`wave:pde1:fig:mesh` illustrate such neighboring mesh points that
contribute to an algebraic equation. In this particular case, we have
sampled the PDE at the point :math:`(2,2)` and constructed
:ref:`(170) <Eq:wave:pde1:step3b>`, which then involves a coupling of :math:`u_nm1^1`,
:math:`u_n^2`, :math:`u_nm1^2`, :math:`u_3^2`, and :math:`u_nm1^3`.  The term *stencil* is often
used about the algebraic equation at a mesh point, and the geometry of
a typical stencil is illustrated in Figure
:ref:`wave:pde1:fig:mesh`. One also often refers to the algebraic
equations as *discrete equations*, *(finite) difference equations* or
a *finite difference scheme*.

.. _wave:pde1:fig:mesh:

.. figure:: stencil_n_interior.png
   :width: 500

   *Mesh in space and time. The circles show points connected in a finite difference equation*

Algebraic version of the initial conditions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We also need to replace the derivative in the initial condition
:ref:`(162) <Eq:wave:pde1:ic:ut>` by a finite difference approximation.
A centered difference of the type

.. math::
        
        \frac{\partial}{\partial t} u(x_i,t_0)\approx
        \frac{u^1_i - u^{-1}_i}{2\Delta t} = [D_{2t} u]^0_i,
        

seems appropriate. Writing out this equation and ordering the terms give

.. _Eq:wave:pde1:step3c:

.. math::

    \tag{172}
    u^{-1}_i=u^{1}_i,\quad i=0,\ldots,N_x{\thinspace .}
        
        

The other initial condition can be computed by

.. math::
         u_i^0 = I(x_i),\quad i=0,\ldots,N_x{\thinspace .}

.. _wave:string:alg:

Formulating a recursive algorithm
---------------------------------

We assume that :math:`u^n_i` and :math:`u^{n-1}_i` are available for
:math:`i=0,\ldots,N_x`.  The only unknown quantity in
:ref:`(170) <Eq:wave:pde1:step3b>` is therefore :math:`u^{n+1}_i`, which we now can
solve for:

.. _Eq:wave:pde1:step4:

.. math::

    \tag{173}
    u^{n+1}_i = -u^{n-1}_i + 2u^n_i + C^2
        \left(u^{n}_{i+1}-2u^{n}_{i} + u^{n}_{i-1}\right){\thinspace .}
        
        

We have here introduced the parameter

.. _Eq:_auto63:

.. math::

    \tag{174}
    C = c\frac{\Delta t}{\Delta x},
        
        

known as the *Courant number*.


.. admonition:: :math:`C` is the key parameter in the discrete wave equation

   
   We see that the discrete version of the PDE features only one
   parameter, :math:`C`, which is therefore the key parameter, together with
   :math:`N_x`, that governs the quality of the numerical solution (see the section :ref:`wave:pde1:analysis` for details). Both the primary physical
   parameter :math:`c` and the numerical parameters :math:`\Delta x` and :math:`\Delta t`
   are lumped together in :math:`C`. Note that :math:`C` is a dimensionless
   parameter.




Given that :math:`u^{n-1}_i` and :math:`u^n_i` are known for :math:`i=0,\ldots,N_x`,
we find new values at the next time level by applying the formula
:ref:`(173) <Eq:wave:pde1:step4>` for :math:`i=1,\ldots,N_x-1`. Figure
:ref:`wave:pde1:fig:mesh` illustrates the points that are used to
compute :math:`u^3_2`. For the boundary points, :math:`i=0` and :math:`i=N_x`, we apply
the boundary conditions :math:`u_i^{n+1}=0`.

Even though sound reasoning leads up to
:ref:`(173) <Eq:wave:pde1:step4>`, there is still a minor challenge with it that needs
to be resolved. Think of the very first computational step to be made.
The scheme :ref:`(173) <Eq:wave:pde1:step4>` is supposed to start at :math:`n=1`, which means
that we compute :math:`u^2` from :math:`u^1` and :math:`u^0`. Unfortunately, we do not know the
value of :math:`u^1`, so how to proceed? A standard procedure in such cases is to
apply :ref:`(173) <Eq:wave:pde1:step4>` also for :math:`n=0`. This immediately seems strange,
since it involves :math:`u^{-1}_i`, which is an undefined
quantity outside the time mesh (and the time domain). However, we can
use the initial condition :ref:`(172) <Eq:wave:pde1:step3c>` in combination with
:ref:`(173) <Eq:wave:pde1:step4>` when :math:`n=0` to eliminate :math:`u^{-1}_i` and
arrive at a special formula for :math:`u_i^1`:

.. _Eq:wave:pde1:step4:1:

.. math::

    \tag{175}
    u_i^1 = u^0_i - \frac{1}{2}
        C^2\left(u^{0}_{i+1}-2u^{0}_{i} + u^{0}_{i-1}\right)
        {\thinspace .}
        
        

Figure :ref:`wave:pde1:fig:stencil:u1` illustrates how :ref:`(175) <Eq:wave:pde1:step4:1>`
connects four instead of five points: :math:`u^1_2`, :math:`u_n^0`, :math:`u_nm1^0`, and :math:`u_3^0`.

.. _wave:pde1:fig:stencil:u1:

.. figure:: stencil_n0_interior.png
   :width: 500

   *Modified stencil for the first time step*

We can now summarize the computational algorithm:

1. Compute :math:`u^0_i=I(x_i)` for :math:`i=0,\ldots,N_x`

2. Compute :math:`u^1_i` by :ref:`(175) <Eq:wave:pde1:step4:1>` and set :math:`u_i^1=0`
   for the boundary points :math:`i=0` and :math:`i=N_x`, for :math:`n=1,2,\ldots,N-1`,

3. For each time level :math:`n=1,2,\ldots,N_t-1`

  a. apply :ref:`(173) <Eq:wave:pde1:step4>` to find :math:`u^{n+1}_i` for :math:`i=1,\ldots,N_x-1`

  b. set :math:`u^{n+1}_i=0` for the boundary points :math:`i=0`, :math:`i=N_x`.

The algorithm essentially consists of moving a finite difference
stencil through all the mesh points, which can be seen as an animation
in a `web page <http://tinyurl.com/pu5uyfn/pub/pub/wave/html/mov-wave/D_stencil_gpl/index.html>`__
or a `movie file <http://tinyurl.com/pu5uyfn/pub/pub/wave/html/mov-wave/D_stencil_gpl/movie.ogg>`__.

.. _wave:string:impl:

Sketch of an implementation
---------------------------

The algorithm only involves the three most recent time levels, so we
need only three arrays for :math:`u_i^{n+1}`, :math:`u_i^n`, and :math:`u_i^{n-1}`,
:math:`i=0,\ldots,N_x`.  Storing all the solutions in a two-dimensional
array of size :math:`(N_x+1)\times (N_t+1)` would be possible in this simple
one-dimensional PDE problem, but is normally out of the question in
three-dimensional (3D) and large two-dimensional (2D) problems. We
shall therefore, in all our PDE solving programs, have the unknown in
memory at as few time levels as possible.

In a Python implementation of this algorithm, we use the array
elements ``u[i]`` to store :math:`u^{n+1}_i`, ``u_n[i]`` to store :math:`u^n_i`, and
``u_nm1[i]`` to store :math:`u^{n-1}_i`.
Our naming convention is to use ``u`` for the
unknown new spatial field to be computed and have all previous time
levels in a list ``u_n`` that we index as ``u_n``, ``u_nm1``, ``u_n[-2]``
and so on. For the wave equation, ``u_n`` has just length 2.

The following Python snippet realizes the steps in the computational
algorithm.

.. code-block:: python

    # Given mesh points as arrays x and t (x[i], t[n])
    dx = x[1] - x[0]
    dt = t[1] - t[0]
    C = c*dt/dx            # Courant number
    Nt = len(t)-1
    C2 = C**2              # Help variable in the scheme
    
    # Set initial condition u(x,0) = I(x)
    for i in range(0, Nx+1):
        u_n[i] = I(x[i])
    
    # Apply special formula for first step, incorporating du/dt=0
    for i in range(1, Nx):
        u[i] = u_n[i] - \ 
               0.5*C**2(u_n[i+1] - 2*u_n[i] + u_n[i-1])
    u[0] = 0;  u[Nx] = 0   # Enforce boundary conditions
    
    # Switch variables before next step
    u_nm1[:], u_n[:] = u_n, u
    
    for n in range(1, Nt):
        # Update all inner mesh points at time t[n+1]
        for i in range(1, Nx):
            u[i] = 2u_n[i] - u_nm1[i] - \ 
                   C**2(u_n[i+1] - 2*u_n[i] + u_n[i-1])
    
        # Insert boundary conditions
        u[0] = 0;  u[Nx] = 0
    
        # Switch variables before next step
        u_nm1[:], u_n[:] = u_n, u

Verification          (4)
=========================

Before implementing the algorithm, it is convenient to add a source
term to the PDE :ref:`(160) <Eq:wave:pde1>`, since that gives us more freedom in
finding test problems for verification. Physically, a source term acts
as a generator for waves in the interior of the domain.

.. _wave:pde2:fd:

A slightly generalized model problem
------------------------------------

We now address the following extended initial-boundary value problem
for one-dimensional wave phenomena:

.. _Eq:wave:pde2:

.. math::

    \tag{176}
    u_{tt} = c^2 u_{xx} + f(x,t), \quad x\in (0,L),\ t\in (0,T]
        
        

.. _Eq:wave:pde2:ic:u:

.. math::

    \tag{177}
    u(x,0) = I(x), \quad x\in [0,L]
        
        

.. _Eq:wave:pde2:ic:ut:

.. math::

    \tag{178}
    u_t(x,0) = V(x), \quad x\in [0,L]
        
        

.. _Eq:wave:pde2:bc:0:

.. math::

    \tag{179}
    u(0,t)  = 0, \quad  t>0
        
        

.. _Eq:wave:pde2:bc:L:

.. math::

    \tag{180}
    u(L,t)  = 0, \quad  t>0
        
        

Sampling the PDE at :math:`(x_i,t_n)` and using the same finite difference
approximations as above, yields

.. _Eq:wave:pde2:fdop:

.. math::

    \tag{181}
    [D_tD_t u = c^2 D_xD_x u + f]^{n}_i
        {\thinspace .}
        
        

Writing this out and solving for the unknown :math:`u^{n+1}_i` results in

.. _Eq:wave:pde2:step3b:

.. math::

    \tag{182}
    u^{n+1}_i = -u^{n-1}_i + 2u^n_i + C^2
        (u^{n}_{i+1}-2u^{n}_{i} + u^{n}_{i-1}) + \Delta t^2 f^n_i
        
        {\thinspace .}
        

The equation for the first time step must be rederived. The discretization
of the initial condition :math:`u_t = V(x)` at :math:`t=0`
becomes

.. math::
         [D_{2t}u = V]^0_i\quad\Rightarrow\quad u^{-1}_i = u^{1}_i - 2\Delta t V_i,

which, when inserted in :ref:`(182) <Eq:wave:pde2:step3b>` for :math:`n=0`, gives
the special formula

.. _Eq:wave:pde2:step3c:

.. math::

    \tag{183}
    u^{1}_i = u^0_i - \Delta t V_i + {\frac{1}{2}}
        C^2
        \left(u^{0}_{i+1}-2u^{0}_{i} + u^{0}_{i-1}\right) + \frac{1}{2}\Delta t^2 f^0_i
        
        {\thinspace .}
        

.. _wave:pde2:fd:standing:waves:

Using an analytical solution of physical significance
-----------------------------------------------------

Many wave problems feature sinusoidal oscillations in time
and space. For example, the original PDE problem
:ref:`(160) <Eq:wave:pde1>`-:ref:`(164) <Eq:wave:pde1:bc:L>` allows an exact solution

.. _Eq:wave:pde2:test:ue:

.. math::

    \tag{184}
    {u_{\small\mbox{e}}}(x,t) = A\sin\left(\frac{\pi}{L}x\right)
        \cos\left(\frac{\pi}{L}ct\right){\thinspace .}
        
        

This :math:`{u_{\small\mbox{e}}}` fulfills the PDE with :math:`f=0`, boundary conditions
:math:`{u_{\small\mbox{e}}}(0,t)={u_{\small\mbox{e}}}(L,0)=0`, as well as initial
conditions :math:`I(x)=A\sin\left(\frac{\pi}{L}x\right)` and :math:`V=0`.


.. admonition:: How to use exact solutions for verification

   It is common to use such exact solutions of physical interest
   to verify implementations. However, the numerical
   solution :math:`u^n_i` will only be an approximation to :math:`{u_{\small\mbox{e}}}(x_i,t_n)`.
   We have no knowledge of the precise size of the error in
   this approximation, and therefore we can never know if discrepancies
   between :math:`u^n_i` and :math:`{u_{\small\mbox{e}}}(x_i,t_n)` are caused
   by mathematical approximations or programming errors.
   In particular, if plots of the computed solution :math:`u^n_i` and
   the exact one :ref:`(184) <Eq:wave:pde2:test:ue>` look similar, many
   are tempted to claim that the implementation works. However,
   even if color plots look nice and the accuracy is "deemed good",
   there can still be serious programming errors present!
   
   The only way to use exact physical solutions like
   :ref:`(184) <Eq:wave:pde2:test:ue>` for serious and thorough verification is to
   run a series of simulations on finer and finer meshes, measure the
   integrated error in each mesh, and from this information estimate the
   empirical convergence rate of the method.




An introduction to the computing of convergence rates is given in
the section
on `convergence rates <http://hplgit.github.io/decay-book/doc/pub/book/sphinx/._book007.html#computing-convergence-rates>`__ in [Ref02]_.
There is also a detailed example on computing convergence rates in
the section :ref:`vib:ode1:verify`.

In the present problem, one expects the method to have a convergence rate
of 2 (see the section :ref:`wave:pde1:analysis`), so if the computed rates
are close to 2 on a sufficiently fine mesh, we have good evidence that
the implementation is free of programming mistakes.

.. _wave:pde2:fd:MMS:

Manufactured solution and estimation of convergence rates
---------------------------------------------------------

Specifying the solution and computing corresponding data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

One problem with the exact solution :ref:`(184) <Eq:wave:pde2:test:ue>` is
that it requires a simplification (:math:`V=0, f=0`) of the implemented problem
:ref:`(176) <Eq:wave:pde2>`-:ref:`(180) <Eq:wave:pde2:bc:L>`. An advantage of using
a *manufactured solution* is that we can test all terms in the
PDE problem. The idea of this approach is to set up some chosen
solution and fit the source term, boundary conditions, and initial
conditions to be compatible with the chosen solution.
Given that our boundary conditions in the implementation are
:math:`u(0,t)=u(L,t)=0`, we must choose a solution that fulfills these
conditions. One example is

.. math::
         {u_{\small\mbox{e}}}(x,t) = x(L-x)\sin t{\thinspace .}

Inserted in the PDE :math:`u_{tt}=c^2u_{xx}+f` we get

.. math::
         -x(L-x)\sin t = -c^2 2\sin t + f\quad\Rightarrow f = (2c^2 - x(L-x))\sin t{\thinspace .}

The initial conditions become

.. math::
        \begin{align*}
        u(x,0) =& I(x) = 0,\\ 
        u_t(x,0) &= V(x) = x(L-x){\thinspace .}
        \end{align*}

Defining a single discretization parameter
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To verify the code, we compute the convergence rates in a series of
simulations, letting each simulation use a finer mesh than the
previous one. Such empirical estimation of convergence rates relies on
an assumption that some measure :math:`E` of the numerical error is related
to the discretization parameters through

.. math::
         E = C_t\Delta t^r + C_x\Delta x^p,

where :math:`C_t`, :math:`C_x`, :math:`r`, and :math:`p` are constants. The constants :math:`r` and
:math:`p` are known as the *convergence rates* in time and space,
respectively.  From the accuracy in the finite difference
approximations, we expect :math:`r=p=2`, since the error terms are of order
:math:`\Delta t^2` and :math:`\Delta x^2`.  This is confirmed by truncation error
analysis and other types of analysis.

By using an exact solution of the PDE problem, we will next compute
the error measure :math:`E` on a sequence of refined meshes and see if
the rates :math:`r=p=2` are obtained. We will not be concerned with estimating
the constants :math:`C_t` and :math:`C_x`, simply because we are not interested in
their values.

It is advantageous to introduce a single discretization parameter
:math:`h=\Delta t=\hat c \Delta x` for some constant :math:`\hat c`.  Since
:math:`\Delta t` and :math:`\Delta x` are related through the Courant number,
:math:`\Delta t = C\Delta x/c`, we set :math:`h=\Delta t`, and then :math:`\Delta x =
hc/C`.  Now the expression for the error measure is greatly
simplified:

.. math::
         E = C_t\Delta t^r + C_x\Delta x^r =
        C_t h^r + C_x\left(\frac{c}{C}\right)^r h^r
        = Dh^r,\quad D = C_t+C_x\left(\frac{c}{C}\right)^r {\thinspace .}

Computing errors
~~~~~~~~~~~~~~~~

We choose an initial discretization parameter :math:`h_0` and run
experiments with decreasing :math:`h`: :math:`h_i=2^{-i}h_0`, :math:`i=1,2,\ldots,m`.
Halving :math:`h` in each experiment is not necessary, but it is a common
choice.  For each experiment we must record :math:`E` and :math:`h`.  A standard
choice of error measure is the :math:`\ell^2` or :math:`\ell^\infty` norm of the
error mesh function :math:`e^n_i`:

.. _Eq:wave:pde2:fd:MMS:E:l2:

.. math::

    \tag{185}
    E = ||e^n_i||_{\ell^2} = \left( \Delta t\Delta x
        \sum_{n=0}^{N_t}\sum_{i=0}^{N_x}
        (e^n_i)^2\right)^{\frac{1}{2}},\quad e^n_i = {u_{\small\mbox{e}}}(x_i,t_n)-u^n_i,
        
        

.. _Eq:wave:pde2:fd:MMS:E:linf:

.. math::

    \tag{186}
    E = ||e^n_i||_{\ell^\infty} = \max_{i,n} |e^i_n|{\thinspace .}
        
        

In Python, one can compute :math:`\sum_{i}(e^{n}_i)^2` at each time step
and accumulate the value in some sum variable, say ``e2_sum``.  At the
final time step one can do ``sqrt(dt*dx*e2_sum)``.  For the
:math:`\ell^\infty` norm one must compare the maximum error at a time level
(``e.max()``) with the global maximum over the time domain: ``e_max =
max(e_max, e.max())``.

An alternative error measure is to use a spatial norm at one time step
only, e.g., the end time :math:`T` (:math:`n=N_t`):

.. _Eq:_auto64:

.. math::

    \tag{187}
    E = ||e^n_i||_{\ell^2} = \left( \Delta x\sum_{i=0}^{N_x}
        (e^n_i)^2\right)^{\frac{1}{2}},\quad e^n_i = {u_{\small\mbox{e}}}(x_i,t_n)-u^n_i,
        
        

.. _Eq:_auto65:

.. math::

    \tag{188}
    E = ||e^n_i||_{\ell^\infty} = \max_{0\leq i\leq N_x} |e^{n}_i|{\thinspace .}
        
        

The important issue is that our error measure :math:`E` must be one number
that represents the error in the simulation.

Computing rates
~~~~~~~~~~~~~~~

Let :math:`E_i` be the error measure in experiment (mesh) number :math:`i` and
let :math:`h_i` be the corresponding discretization parameter (:math:`h`).
With the error model :math:`E_i = Dh_i^r`, we can
estimate :math:`r` by comparing two consecutive
experiments:

.. math::
        \begin{align*}
        E_{i+1}& =D h_{i+1}^{r},\\ 
        E_{i}& =D h_{i}^{r}{\thinspace .}
        \end{align*}

Dividing the two equations eliminates the (uninteresting) constant :math:`D`.
Thereafter, solving for :math:`r` yields

.. math::
         r = \frac{\ln E_{i+1}/E_{i}}{\ln h_{i+1}/h_{i}}{\thinspace .}
        

Since :math:`r` depends on :math:`i`, i.e., which simulations we compare,
we add an index to :math:`r`: :math:`r_i`, where :math:`i=0,\ldots,m-2`, if we
have :math:`m` experiments: :math:`(h_0,E_0),\ldots,(h_{m-1}, E_{m-1})`.

In our present discretization of the wave equation we expect :math:`r=2`, and
hence the :math:`r_i` values should converge to 2 as :math:`i` increases.

.. _wave:pde2:fd:verify:quadratic:

Constructing an exact solution of the discrete equations
--------------------------------------------------------

With a manufactured or known analytical solution, as outlined above,
we can estimate convergence rates and see if they have the correct
asymptotic behavior. Experience shows that this is a quite good
verification technique in that many common bugs will destroy the
convergence rates. A significantly better test though,
would be to check that the
numerical solution is exactly what it should be. This will in general
require exact knowledge of the numerical error, which we do not normally have
(although we in the section :ref:`wave:pde1:analysis` establish such knowledge
in simple cases).
However, it is possible to look for solutions where we can show that
the numerical error vanishes, i.e., the solution of the original continuous
PDE problem is
also a solution of the discrete equations. This property often arises
if the exact solution of the PDE
is a lower-order polynomial. (Truncation error
analysis leads to error measures that involve derivatives of the
exact solution. In the present problem, the truncation error involves
4th-order derivatives of :math:`u` in space and time. Choosing :math:`u`
as a polynomial of degree three or less
will therefore lead to vanishing error.)

We shall now illustrate the construction of an exact solution to both the
PDE itself and the discrete equations.
Our chosen manufactured solution is quadratic in space
and linear in time. More specifically, we set

.. _Eq:wave:pde2:fd:verify:quadratic:uex:

.. math::

    \tag{189}
    {u_{\small\mbox{e}}} (x,t) = x(L-x)(1+{\frac{1}{2}}t),
        
        

which by insertion in the PDE leads to :math:`f(x,t)=2(1+t)c^2`. This :math:`{u_{\small\mbox{e}}}`
fulfills the boundary conditions :math:`u=0` and demands :math:`I(x)=x(L-x)`
and :math:`V(x)={\frac{1}{2}}x(L-x)`.

To realize that the chosen :math:`{u_{\small\mbox{e}}}` is also an exact
solution of the discrete equations,
we first remind ourselves that :math:`t_n=n\Delta t` before we
establish that

.. _Eq:_auto66:

.. math::

    \tag{190}
    \lbrack D_tD_t t^2\rbrack^n = \frac{t_{n+1}^2 - 2t_n^2 + t_{n-1}^2}{\Delta t^2}
        = (n+1)^2 -2n^2 + (n-1)^2 = 2,
        
        

.. _Eq:_auto67:

.. math::

    \tag{191}
    \lbrack D_tD_t t\rbrack^n = \frac{t_{n+1} - 2t_n + t_{n-1}}{\Delta t^2}
        = \frac{((n+1) -2n + (n-1))\Delta t}{\Delta t^2} = 0
        {\thinspace .}
        
        

Hence,

.. math::
         [D_tD_t {u_{\small\mbox{e}}}]^n_i = x_i(L-x_i)[D_tD_t (1+{\frac{1}{2}}t)]^n =
        x_i(L-x_i){\frac{1}{2}}[D_tD_t t]^n = 0{\thinspace .}

Similarly, we get that

.. math::
        \begin{align*}
        \lbrack D_xD_x {u_{\small\mbox{e}}}\rbrack^n_i &=
        (1+{\frac{1}{2}}t_n)\lbrack D_xD_x (xL-x^2)\rbrack_i\\ 
        & =
        (1+{\frac{1}{2}}t_n)\lbrack LD_xD_x x - D_xD_x x^2\rbrack_i \\ 
        &= -2(1+{\frac{1}{2}}t_n)
        {\thinspace .}
        \end{align*}

Now, :math:`f^n_i = 2(1+{\frac{1}{2}}t_n)c^2`, which results in

.. math::
         [D_tD_t {u_{\small\mbox{e}}} - c^2D_xD_x{u_{\small\mbox{e}}} - f]^n_i = 0 +
        c^2 2(1 + {\frac{1}{2}}t_{n}) +
        2(1+{\frac{1}{2}}t_n)c^2 = 0{\thinspace .}

Moreover, :math:`{u_{\small\mbox{e}}}(x_i,0)=I(x_i)`,
:math:`\partial {u_{\small\mbox{e}}}/\partial t = V(x_i)` at :math:`t=0`, and
:math:`{u_{\small\mbox{e}}}(x_0,t)={u_{\small\mbox{e}}}(x_{N_x},0)=0`. Also the modified scheme for the
first time step is fulfilled by :math:`{u_{\small\mbox{e}}}(x_i,t_n)`.

Therefore, the exact solution :math:`{u_{\small\mbox{e}}}(x,t)=x(L-x)(1+t/2)` of the PDE
problem is also an exact solution of the discrete problem.  This means
that we know beforehand what numbers the numerical algorithm should
produce.  We can use this fact to check that the computed :math:`u^n_i`
values from an implementation equals :math:`{u_{\small\mbox{e}}}(x_i,t_n)`, within machine
precision.  This result is valid *regardless of the mesh spacings*
:math:`\Delta x` and :math:`\Delta t`!  Nevertheless, there might be stability
restrictions on :math:`\Delta x` and :math:`\Delta t`, so the test can only be run
for a mesh that is compatible with the stability criterion (which in
the present case is :math:`C\leq 1`, to be derived later).


.. note::
   A product of quadratic or linear expressions in the various
   independent variables, as shown above, will often fulfill both the
   PDE problem and the discrete equations, and can therefore be very useful
   solutions for verifying implementations.
   
   However, for 1D wave
   equations of the type :math:`u_{tt}=c^2u_{xx}` we shall see that there is always
   another much more powerful way of generating exact
   solutions (which consists in just setting :math:`C=1` (!), as shown in
   the section :ref:`wave:pde1:analysis`).




.. _wave:pde1:impl:

Implementation          (4)
===========================

.. index::
   single: wave equation; 1D, implementation

This section presents the complete computational algorithm, its
implementation in Python code, animation of the solution, and
verification of the implementation.

A real implementation of the basic computational algorithm from
the sections :ref:`wave:string:alg` and :ref:`wave:string:impl` can be
encapsulated in a function, taking all the input data for the problem
as arguments.  The physical input data consists of :math:`c`, :math:`I(x)`,
:math:`V(x)`, :math:`f(x,t)`, :math:`L`, and :math:`T`.  The numerical input is the mesh
parameters :math:`\Delta t` and :math:`\Delta x`.

Instead of specifying :math:`\Delta t` *and* :math:`\Delta x`, we can specify one
of them and the Courant number :math:`C` instead, since having explicit
control of the Courant number is convenient when investigating the
numerical method. Many find it natural to prescribe the resolution of
the spatial grid and set :math:`N_x`. The solver function can then compute
:math:`\Delta t = CL/(cN_x)`. However, for comparing :math:`u(x,t)` curves (as
functions of :math:`x`) for various Courant numbers
it is more convenient to keep :math:`\Delta t` fixed for
all :math:`C` and let :math:`\Delta x` vary according to :math:`\Delta x = c\Delta t/C`.
With :math:`\Delta t` fixed, all frames correspond to the same time :math:`t`,
and this simplifies animations that compare simulations with different
mesh resolutions. Plotting functions of :math:`x`
with different spatial resolution is trivial,
so it is easier to let :math:`\Delta x` vary in the simulations than :math:`\Delta t`.

.. _wave:pde1:impl:useraction:

Callback function for user-specific actions
-------------------------------------------

.. index:: callback function

The solution at all spatial points at a new time level is stored in an
array ``u`` of length :math:`N_x+1`. We need to decide what to do with
this solution, e.g., visualize the curve, analyze the values, or write
the array to file for later use. The decision about what to do is left to
the user in the form of a user-supplied function

.. code-block:: python

    user_action(u, x, t, n)

where ``u`` is the solution at the spatial points ``x`` at time ``t[n]``.
The ``user_action`` function is called from the solver at each time level ``n``.

If the user wants to plot the solution or store the solution at a
time point, she needs to write such a function and take appropriate
actions inside it. We will show examples on many such ``user_action``
functions.

Since the solver function makes calls back to the user's code
via such a function, this type of function is called a *callback function*.
When writing general software, like our solver function, which also needs
to carry out special problem- or solution-dependent actions
(like visualization),
it is a common technique to leave those actions to user-supplied
callback functions.

The callback function can be used to terminate the solution process
if the user returns ``True``. For example,

.. code-block:: python

    def my_user_action_function(u, x, t, n):
        return np.abs(u).max() > 10

is a callback function that will terminate the solver function of the
amplitude of the waves exceed 10, which is here considered as a numerical
instability.

.. _wave:pde1:impl:solver:

The solver function
-------------------

A first attempt at a solver function is listed below.

.. code-block:: python

    import numpy as np
    
    def solver(I, V, f, c, L, dt, C, T, user_action=None):
        """Solve u_tt=c^2*u_xx + f on (0,L)x(0,T]."""
        Nt = int(round(T/dt))
        t = np.linspace(0, Nt*dt, Nt+1)   # Mesh points in time
        dx = dt*c/float(C)
        Nx = int(round(L/dx))
        x = np.linspace(0, L, Nx+1)       # Mesh points in space
        C2 = C**2                         # Help variable in the scheme
        # Make sure dx and dt are compatible with x and t
        dx = x[1] - x[0]
        dt = t[1] - t[0]
    
        if f is None or f == 0 :
            f = lambda x, t: 0
        if V is None or V == 0:
            V = lambda x: 0
    
        u     = np.zeros(Nx+1)   # Solution array at new time level
        u_n   = np.zeros(Nx+1)   # Solution at 1 time level back
        u_nm1 = np.zeros(Nx+1)   # Solution at 2 time levels back
    
        import time;  t0 = time.clock()  # Measure CPU time
    
        # Load initial condition into u_n
        for i in range(0,Nx+1):
            u_n[i] = I(x[i])
    
        if user_action is not None:
            user_action(u_n, x, t, 0)
    
        # Special formula for first time step
        n = 0
        for i in range(1, Nx):
            u[i] = u_n[i] + dt*V(x[i]) + \ 
                   0.5*C2*(u_n[i-1] - 2*u_n[i] + u_n[i+1]) + \ 
                   0.5*dt**2*f(x[i], t[n])
        u[0] = 0;  u[Nx] = 0
    
        if user_action is not None:
            user_action(u, x, t, 1)
    
        # Switch variables before next step
        u_nm1[:] = u_n;  u_n[:] = u
    
        for n in range(1, Nt):
            # Update all inner points at time t[n+1]
            for i in range(1, Nx):
                u[i] = - u_nm1[i] + 2*u_n[i] + \ 
                         C2*(u_n[i-1] - 2*u_n[i] + u_n[i+1]) + \ 
                         dt**2*f(x[i], t[n])
    
            # Insert boundary conditions
            u[0] = 0;  u[Nx] = 0
            if user_action is not None:
                if user_action(u, x, t, n+1):
                    break
    
            # Switch variables before next step
            u_nm1[:] = u_n;  u_n[:] = u
    
        cpu_time = time.clock() - t0
        return u, x, t, cpu_time

A couple of remarks about the above code is perhaps necessary:

 * Although we give ``dt`` and compute ``dx`` via ``C`` and ``c``, the resulting
   ``t`` and ``x`` meshes do not necessarily correspond exactly to these values
   because of rounding errors. To explicitly ensure that ``dx`` and ``dt``
   correspond to the cell sizes in ``x`` and ``t``, we recompute the values.

 * According to the convention described in the section :ref:`wave:pde1:impl:useraction`, a true value returned from ``user_action`` should terminate the simulation, here implemented by a ``break`` statement inside the for loop in the solver.

.. Too trivial here:

.. Checking that a solution :math:`u^n_i` stays constant throughout some

.. time steps is often of considerable help in tracking down bugs

.. in an implementation. A constant solution :math:`{u_{\small\mbox{e}}} = Q` fulfills

.. the PDE problem :ref:`(176) <Eq:wave:pde2>`-:ref:`(180) <Eq:wave:pde2:bc:L>`

.. if :math:`I(x)=0`, :math:`V=0`, :math:`u(0,t)=u(L,t)=0`, and :math:`f=0`

.. _wave:pde1:impl:verify:quadratic:

Verification: exact quadratic solution
--------------------------------------

.. index::
   single: verification; polynomial solution

.. index:: nose

.. index:: pytest

.. index:: unit testing

.. index:: test function

We use the test problem derived in the section :ref:`wave:pde2:fd` for
verification. Below is a unit test based on this test problem
and realized as a proper *test function* compatible with the unit test
frameworks nose or pytest.

.. code-block:: python

    def test_quadratic():
        """Check that u(x,t)=x(L-x)(1+t/2) is exactly reproduced."""
    
        def u_exact(x, t):
            return x*(L-x)*(1 + 0.5*t)
    
        def I(x):
            return u_exact(x, 0)
    
        def V(x):
            return 0.5*u_exact(x, 0)
    
        def f(x, t):
            return 2*(1 + 0.5*t)*c**2
    
        L = 2.5
        c = 1.5
        C = 0.75
        Nx = 6  # Very coarse mesh for this exact test
        dt = C*(L/Nx)/c
        T = 18
    
        def assert_no_error(u, x, t, n):
            u_e = u_exact(x, t[n])
            diff = np.abs(u - u_e).max()
            tol = 1E-13
            assert diff < tol
    
        solver(I, V, f, c, L, dt, C, T,
               user_action=assert_no_error)

When this function resides in the file ``wave1D_u0.py``, one can run
pytest to check that all test functions with names ``test_*()``
in this file work:

.. code-block:: text

    Terminal> py.test -s -v wave1D_u0.py

.. _wave:pde1:impl:verify:rate:

Verification: convergence rates          (1)
--------------------------------------------

A more general method, but not so reliable as a verification method,
is to compute the convergence rates and see if they coincide with
theoretical estimates. Here we expect a rate of 2 according to
the various results in the section :ref:`wave:pde1:analysis`.
A general function for computing convergence rates can be written like
this:

.. code-block:: python

    def convergence_rates(
        u_exact,                 # Python function for exact solution
        I, V, f, c, L,           # physical parameters
        dt0, num_meshes, C, T):  # numerical parameters
        """
        Half the time step and estimate convergence rates for
        for num_meshes simulations.
        """
        # First define an appropriate user action function
        global error
        error = 0  # error computed in the user action function
    
        def compute_error(u, x, t, n):
            global error  # must be global to be altered here
            # (otherwise error is a local variable, different
            # from error defined in the parent function)
            if n == 0:
                error = 0
            else:
                error = max(error, np.abs(u - u_exact(x, t[n])).max())
    
        # Run finer and finer resolutions and compute true errors
        E = []
        h = []  # dt, solver adjusts dx such that C=dt*c/dx
        dt = dt0
        for i in range(num_meshes):
            solver(I, V, f, c, L, dt, C, T,
                   user_action=compute_error)
            # error is computed in the final call to compute_error
            E.append(error)
            h.append(dt)
            dt /= 2  # halve the time step for next simulation
        print 'E:', E
        print 'h:', h
        # Convergence rates for two consecutive experiments
        r = [np.log(E[i]/E[i-1])/np.log(h[i]/h[i-1])
             for i in range(1,num_meshes)]
        return r

Using the analytical solution from the section :ref:`wave:pde2:fd:standing:waves`, we can call ``convergece_rates`` to
see if we get a convergence rate that approaches 2 and use the final
estimate of the rate in an ``assert`` statement such that this function becomes
a proper test function:

.. code-block:: python

    def test_convrate_sincos():
        n = m = 2
        L = 1.0
        u_exact = lambda x, t: np.cos(m*np.pi/L*t)*np.sin(m*np.pi/L*x)
    
        r = convergence_rates(
            u_exact=u_exact,
            I=lambda x: u_exact(x, 0),
            V=lambda x: 0,
            f=0,
            c=1,
            L=L,
            dt0=0.1,
            num_meshes=6,
            C=0.9,
            T=1)
        print 'rates sin(x)*cos(t) solution:', \ 
              [round(r_,2) for r_ in r]
        assert abs(r[-1] - 2) < 0.002

Doing ``py.test -s -v wave1D_u0.py`` will run also this test function and
show the rates 2.05, 1.98, 2.0, 2.0, and 2.0 (to two decimals).

.. _wave:pde1:impl:animate:

Visualization: animating the solution
-------------------------------------

Now that we have verified the implementation it is time to do a
real computation where we also display evolution of the waves
on the screen. Since the ``solver`` function knows nothing about
what type of visualizations we may want, it calls the callback function
``user_action(u, x, t, n)``. We must therefore write this function and
find the proper statements for plotting the solution.

Function for administering the simulation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following ``viz`` function

1. defines a ``user_action`` callback function
   for plotting the solution at each time level,

2. calls the ``solver`` function, and

3. combines all the plots (in files) to video in different formats.

.. code-block:: python

    def viz(
        I, V, f, c, L, dt, C, T,  # PDE parameters
        umin, umax,               # Interval for u in plots
        animate=True,             # Simulation with animation?
        tool='matplotlib',        # 'matplotlib' or 'scitools'
        solver_function=solver,   # Function with numerical algorithm
        ):
        """Run solver and visualize u at each time level."""
    
        def plot_u_st(u, x, t, n):
            """user_action function for solver."""
            plt.plot(x, u, 'r-',
                     xlabel='x', ylabel='u',
                     axis=[0, L, umin, umax],
                     title='t=%f' % t[n], show=True)
            # Let the initial condition stay on the screen for 2
            # seconds, else insert a pause of 0.2 s between each plot
            time.sleep(2) if t[n] == 0 else time.sleep(0.2)
            plt.savefig('frame_%04d.png' % n)  # for movie making
    
        class PlotMatplotlib:
            def __call__(self, u, x, t, n):
                """user_action function for solver."""
                if n == 0:
                    plt.ion()
                    self.lines = plt.plot(x, u, 'r-')
                    plt.xlabel('x');  plt.ylabel('u')
                    plt.axis([0, L, umin, umax])
                    plt.legend(['t=%f' % t[n]], loc='lower left')
                else:
                    self.lines[0].set_ydata(u)
                    plt.legend(['t=%f' % t[n]], loc='lower left')
                    plt.draw()
                time.sleep(2) if t[n] == 0 else time.sleep(0.2)
                plt.savefig('tmp_%04d.png' % n)  # for movie making
    
        if tool == 'matplotlib':
            import matplotlib.pyplot as plt
            plot_u = PlotMatplotlib()
        elif tool == 'scitools':
            import scitools.std as plt  # scitools.easyviz interface
            plot_u = plot_u_st
        import time, glob, os
    
        # Clean up old movie frames
        for filename in glob.glob('tmp_*.png'):
            os.remove(filename)
    
        # Call solver and do the simulaton
        user_action = plot_u if animate else None
        u, x, t, cpu = solver_function(
            I, V, f, c, L, dt, C, T, user_action)
    
        # Make video files
        fps = 4  # frames per second
        codec2ext = dict(flv='flv', libx264='mp4', libvpx='webm',
                         libtheora='ogg')  # video formats
        filespec = 'tmp_%04d.png'
        movie_program = 'ffmpeg'  # or 'avconv'
        for codec in codec2ext:
            ext = codec2ext[codec]
            cmd = '%(movie_program)s -r %(fps)d -i %(filespec)s '\ 
                  '-vcodec %(codec)s movie.%(ext)s' % vars()
            os.system(cmd)
    
        if tool == 'scitools':
            # Make an HTML play for showing the animation in a browser
            plt.movie('tmp_*.png', encoder='html', fps=fps,
                      output_file='movie.html')
        return cpu

Dissection of the code
~~~~~~~~~~~~~~~~~~~~~~

The ``viz`` function can either use SciTools or Matplotlib for
visualizing the solution. The ``user_action`` function based on SciTools
is called ``plot_u_st``, while the ``user_action`` function based on
Matplotlib is a bit more complicated as it is realized as a class and
needs statements that differ from those for making static plots.
SciTools can utilize both Matplotlib and Gnuplot (and many other
plotting programs) for doing the graphics, but Gnuplot is a relevant
choice for large :math:`N_x` or in two-dimensional problems
as Gnuplot is significantly faster than
Matplotlib for screen animations.

.. index:: closure

A function inside another function, like ``plot_u_st`` in the above code
segment, has access to *and remembers* all the local variables in the
surrounding code inside the ``viz`` function (!). This is known in
computer science as a *closure* and is very convenient to program
with. For example, the ``plt`` and ``time`` modules defined outside
``plot_u`` are accessible for ``plot_u_st`` when the function is called
(as ``user_action``) in the ``solver`` function.  Some may think, however,
that a class instead of a closure is a cleaner and
easier-to-understand implementation of the user action function, see
the section :ref:`wave:pde2:software`.

The ``plot_u_st`` function just makes a standard SciTools ``plot`` command
for plotting ``u`` as a function of ``x`` at time ``t[n]``.  To achieve a
smooth animation, the ``plot`` command should take keyword arguments
instead of being broken into separate calls to ``xlabel``, ``ylabel``,
``axis``, ``time``, and ``show``.  Several ``plot`` calls will automatically
cause an animation on the screen. In addition, we want to save each
frame in the animation to file. We then need a filename where the
frame number is padded with zeros, here ``tmp_0000.png``,
``tmp_0001.png``, and so on.  The proper printf construction is then
``tmp_%04d.png``.
The section :ref:`vib:ode1:anim` contains more basic
information on making animations.

The solver is called with an argument ``plot_u`` as ``user_function``.
If the user chooses to use SciTools, ``plot_u`` is the ``plot_u_st``
callback function, but for Matplotlib it is an instance of the
class ``PlotMatplotlib``. Also this class makes use of variables
defined in the ``viz`` function: ``plt`` and ``time``.
With Matplotlib, one has to make the first plot the standard way, and
then update the :math:`y` data in the plot at every time level. The update
requires active use of the returned value from ``plt.plot`` in the first
plot.  This value would need to be stored in a local variable if we
were to use a closure for the ``user_action`` function when doing the
animation with Matplotlib. It is much easier to store the
variable as a class attribute ``self.lines``. Since the class is essentially a
function, we implement the function as the special method ``__call__``
such that the instance ``plot_u(u, x, t, n)`` can be called as a standard
callback function from ``solver``.

Making movie files
~~~~~~~~~~~~~~~~~~

From the
``frame_*.png`` files containing the frames in the animation we can
make video files.
The section :ref:`vib:ode1:anim` presents basic information on how to
use the ``ffmpeg`` (or ``avconv``) program for producing video files
in different modern formats: Flash, MP4, Webm, and Ogg.

The ``viz`` function creates an ``ffmpeg`` or ``avconv`` command
with the proper arguments for each of the formats Flash, MP4, WebM,
and Ogg. The task is greatly simplified by having a
``codec2ext`` dictionary for mapping
video codec names to filename extensions.
As mentioned in the section :ref:`vib:ode1:anim`, only
two formats are actually needed to ensure that all browsers can
successfully play the video: MP4 and WebM.

Some animations having a large number of plot files may not
be properly combined into a video using ``ffmpeg`` or ``avconv``.
A method that always works is to play the PNG files as an animation
in a browser using JavaScript code in an HTML file.
The SciTools package has a function ``movie`` (or a stand-alone command
``scitools movie``) for creating such an HTML player. The ``plt.movie``
call in the ``viz`` function shows how the function is used.
The file ``movie.html`` can be loaded into a browser and features
a user interface where the speed of the animation can be controlled.
Note that the movie in this case consists of the ``movie.html`` file
and all the frame files ``tmp_*.png``.

Skipping frames for animation speed
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Sometimes the time step is small and :math:`T` is large, leading to an
inconveniently large number of plot files and a slow animation on the
screen. The solution to such a problem is to decide on a total number
of frames in the animation, ``num_frames``, and plot the solution only for
every ``skip_frame`` frames. For example, setting ``skip_frame=5`` leads
to plots of every 5 frames. The default value ``skip_frame=1`` plots
every frame.
The total number of time levels (i.e., maximum
possible number of frames) is the length of ``t``, ``t.size`` (or ``len(t)``),
so if we want ``num_frames`` frames in the animation,
we need to plot every ``t.size/num_frames`` frames:

.. code-block:: python

    skip_frame = int(t.size/float(num_frames))
    if n % skip_frame == 0 or n == t.size-1:
        st.plot(x, u, 'r-', ...)

The initial condition (``n=0``) is included by ``n % skip_frame == 0``,
as well as every ``skip_frame``-th frame.
As ``n % skip_frame == 0`` will very seldom be true for the
very final frame, we must also check if ``n == t.size-1`` to
get the final frame included.

A simple choice of numbers may illustrate the formulas: say we have
801 frames in total (``t.size``) and we allow only 60 frames to be
plotted. As ``n`` then runs from 801 to 0, we need to plot every 801/60
frame, which with integer division yields 13 as ``skip_frame``. Using
the mod function, ``n % skip_frame``, this operation is zero every time
``n`` can be divided by 13 without a remainder. That is, the ``if`` test
is true when ``n`` equals :math:`0, 13, 26, 39, ..., 780, 801`. The associated
code is included in the ``plot_u`` function, inside the ``viz`` function,
in the file `wave1D_u0.py <http://tinyurl.com/nu656p2/wave/wave1D/wave1D_u0.py>`__.

.. _wave:pde1:guitar:data:

Running a case
--------------

The first demo of our 1D wave equation solver concerns vibrations of a
string that is initially deformed to a triangular shape, like when picking
a guitar string:

.. _Eq:wave:pde1:guitar:I:

.. math::

    \tag{192}
    I(x) = \left\lbrace
        \begin{array}{ll}
        ax/x_0, & x < x_0,\\ 
        a(L-x)/(L-x_0), & \hbox{otherwise}
        \end{array}\right.
        
        

We choose :math:`L=75` cm, :math:`x_0=0.8L`, :math:`a=5` mm, and a time frequency
:math:`\nu = 440` Hz. The relation between the wave speed :math:`c` and :math:`\nu` is
:math:`c=\nu\lambda`, where :math:`\lambda` is the wavelength, taken as :math:`2L` because
the longest wave on the string forms half a wavelength. There is no
external force, so :math:`f=0` (meaning we can neglect gravity),
and the string is at rest initially, implying :math:`V=0`.

Regarding numerical parameters, we need to specify a :math:`\Delta t`.
Sometimes it is more natural to think of a spatial resolution instead
of a time step. A natural semi-coarse spatial resolution in the present
problem is :math:`N_x=50`. We can then choose the associated :math:`\Delta t` (as required
by the ``viz`` and ``solver`` functions) as the stability limit:
:math:`\Delta t = L/(N_xc)`. This is the :math:`\Delta t` to be specified,
but notice that if :math:`C<1`, the actual :math:`\Delta x` computed in ``solver`` gets
larger than :math:`L/N_x`: :math:`\Delta x = c\Delta t/C = L/(N_xC)`. (The reason
is that we fix :math:`\Delta t` and adjust :math:`\Delta x`, so if :math:`C` gets
smaller, the code implements this effect in terms of a larger :math:`\Delta x`.)

A function for setting the physical and numerical parameters and
calling ``viz`` in this application goes as follows:

.. code-block:: python

    def guitar(C):
        """Triangular wave (pulled guitar string)."""
        L = 0.75
        x0 = 0.8*L
        a = 0.005
        freq = 440
        wavelength = 2*L
        c = freq*wavelength
        omega = 2*pi*freq
        num_periods = 1
        T = 2*pi/omega*num_periods
        # Choose dt the same as the stability limit for Nx=50
        dt = L/50./c
    
        def I(x):
            return a*x/x0 if x < x0 else a/(L-x0)*(L-x)
    
        umin = -1.2*a;  umax = -umin
        cpu = viz(I, 0, 0, c, L, dt, C, T, umin, umax,
                  animate=True, tool='scitools')

The associated program has the name `wave1D_u0.py <http://tinyurl.com/nu656p2/wave/wave1D/wave1D_u0.py>`__. Run
the program and watch the `movie of the vibrating string <http://tinyurl.com/pu5uyfn/pub/pub/wave/html/mov-wave/guitar_C0.8/movie.html>`__.
The string should ideally consist of straight segments, but these are
somewhat wavy due to numerical approximation. Run the case with the
``wave1D_u0.py`` code and :math:`C=1` to see the exact solution.

Working with a scaled PDE model
-------------------------------

Depending on the model, it may be a substantial job to establish
consistent and relevant physical parameter values for a case.  The
guitar string example illustrates the point.  However, by *scaling*
the mathematical problem we can often reduce the need to estimate
physical parameters dramatically. The scaling technique consists of
introducing new independent and dependent variables, with the aim that
the absolute values of these lie in :math:`[0,1]`. We introduce the
dimensionless variables (details are found in the section
`Homogeneous Dirichlet conditions in 1D <http://hplgit.github.io/scaling-book/doc/pub/book/html/._scaling-book007.html#sec:scale:wave:bc_u0>`__
in the book `Scaling of differential equations <http://tinyurl.com/qfjgxmf/web>`__ [Ref03]_

.. math::
         \bar x = \frac{x}{L},\quad \bar t = \frac{c}{L}t,\quad
        \bar u = \frac{u}{a}
        {\thinspace .}
        

Here, :math:`L` is a typical length scale, e.g., the length of the domain,
and :math:`a` is a typical size of :math:`u`, e.g., determined from the
initial condition: :math:`a=\max_x|I(x)|`.

We get by the chain rule that

.. math::
         \frac{\partial u}{\partial t} =
        \frac{\partial}{\partial\bar t}\left(a\bar u\right)
        \frac{d\bar t}{dt} =
        \frac{ac}{L}\frac{\partial\bar u}{\partial\bar t}{\thinspace .}

Similarly,

.. math::
         \frac{\partial u}{\partial x}
        = \frac{a}{L}\frac{\partial\bar u}{\partial\bar x}{\thinspace .}

Inserting the dimensionless variables in the PDE gives, in case :math:`f=0`,

.. math::
         \frac{a^2c^2}{L^2}\frac{\partial^2\bar u}{\partial\bar t^2}
        = \frac{a^2c^2}{L^2}\frac{\partial^2\bar u}{\partial\bar x^2}{\thinspace .}

Dropping the bars, we arrive at the scaled PDE

.. _Eq:_auto68:

.. math::

    \tag{193}
    \frac{\partial^2 u}{\partial t^2} = \frac{\partial^2 u}{\partial x^2},
        \quad x\in (0,1),\ t\in (0,cT/L),
        
        

which has no parameter :math:`c^2` anymore. The initial conditions are scaled
as

.. math::
         a\bar u(\bar x, 0) = I(L\bar x)

and

.. math::
         \frac{a}{L/c}\frac{\partial\bar u}{\partial\bar t}(\bar x,0) = V(L\bar x),

resulting in

.. math::
         \bar u(\bar x, 0) = \frac{I(L\bar x)}{\max_x |I(x)|},\quad
        \frac{\partial\bar u}{\partial\bar t}(\bar x,0) = \frac{L}{ac}V(L\bar x){\thinspace .}

In the common case :math:`V=0` we see that there are no physical parameters to be
estimated in the PDE model!

If we have a program implemented for the physical wave equation with
dimensions, we can obtain the dimensionless, scaled version by
setting :math:`c=1`. The initial condition of a guitar string,
given in :ref:`(192) <Eq:wave:pde1:guitar:I>`, gets its scaled form by choosing
:math:`a=1`, :math:`L=1`, and :math:`x_0\in [0,1]`. This means that we only need to
decide on the :math:`x_0` value as a fraction of unity, because
the scaled problem corresponds to setting all
other parameters to unity. In the code we can just set
``a=c=L=1``, ``x0=0.8``, and there is no need to calculate with
wavelengths and frequencies to estimate :math:`c`!

The only non-trivial parameter to estimate in the scaled problem
is the final end time of the simulation, or more precisely, how it relates
to periods in periodic solutions in time, since we often want to
express the end time as a certain number of periods.
The period in the dimensionless problem is 2, so the end time can be
set to the desired number of periods times 2.

Why the dimensionless period is 2 can be explained by the following
reasoning.
Suppose that :math:`u` behaves as :math:`\cos (\omega t)` in time in the original
problem with dimensions. The corresponding period is then :math:`P=2\pi/\omega`, but
we need to estimate :math:`\omega`. A typical solution of the wave
equation is :math:`u(x,t)=A\cos(kx)\cos(\omega t)`, where :math:`A` is an amplitude
and :math:`k` is related to the wave length :math:`\lambda` in space: :math:`\lambda = 2\pi/k`.
Both :math:`\lambda` and :math:`A` will be given by the initial condition :math:`I(x)`.
Inserting this :math:`u(x,t)` in the PDE yields :math:`-\omega^2 = -c^2k^2`, i.e.,
:math:`\omega = kc`. The period is therefore :math:`P=2\pi/(kc)`.
If the boundary conditions are :math:`u(0,t)=u(L,t)`, we need to have
:math:`kL = n\pi` for integer :math:`n`. The period becomes :math:`P=2L/nc`. The longest
period is :math:`P=2L/c`. The dimensionless period :math:`\tilde P` is obtained
by dividing :math:`P` by the time scale :math:`L/c`, which results in :math:`\tilde P=2`.
Shorter waves in the initial condition will have a dimensionless
shorter period :math:`\tilde P=2/n` (:math:`n>1`).

.. _wave:pde1:impl:vec:

Vectorization
=============

.. index:: vectorization

.. index:: parallelism

The computational algorithm for solving the wave equation visits one
mesh point at a time and evaluates a formula for the new value
:math:`u_i^{n+1}` at that point. Technically, this is implemented by a loop
over array elements in a program. Such loops may run slowly in Python
(and similar interpreted languages such as R and MATLAB).  One
technique for speeding up loops is to perform operations on entire
arrays instead of working with one element at a time. This is referred
to as *vectorization*, *vector computing*, or *array computing*.
Operations on whole arrays are possible if the computations involving
each element is independent of each other and therefore can, at least
in principle, be performed simultaneously.  That is, vectorization not
only speeds up the code on serial computers, but also makes it easy to
exploit parallel computing. Actually, there are Python tools like
`Numba <http://numba.pydata.org>`__ that can automatically turn
vectorized code into parallel code.

.. _wave:pde1:impl:vec:slices:basics:

Operations on slices of arrays
------------------------------

.. index:: scalar code

.. index:: vectorization

.. index:: array computing

.. index:: array slices

.. index:: slice

Efficient computing with ``numpy`` arrays demands that we avoid loops
and compute with entire arrays at once (or at least large portions of them).
Consider this calculation of differences :math:`d_i = u_{i+1}-u_i`:

.. code-block:: python

    n = u.size
    for i in range(0, n-1):
        d[i] = u[i+1] - u[i]

All the differences here are independent of each other.
The computation of ``d`` can therefore alternatively be done by
subtracting the array :math:`(u_0,u_n,\ldots,u_{n-1})` from
the array where the elements are shifted one index upwards:
:math:`(u_n,u_nm1,\ldots,u_n)`, see Figure :ref:`wave:pde1:vec:fig1`.
The former subset of the array can be
expressed by ``u[0:n-1]``,
``u[0:-1]``, or just
``u[:-1]``, meaning from index 0 up to,
but not including, the last element (``-1``). The latter subset
is obtained by ``u[1:n]`` or ``u[1:]``,
meaning from index 1 and the rest of the array.
The computation of ``d`` can now be done without an explicit Python loop:

.. code-block:: python

    d = u[1:] - u[:-1]

or with explicit limits if desired:

.. code-block:: python

    d = u[1:n] - u[0:n-1]

Indices with a colon, going from an index to (but not including) another
index are called *slices*. With ``numpy`` arrays, the computations
are still done by loops, but in efficient, compiled, highly optimized
C or Fortran code. Such loops are sometimes referred to as *vectorized
loops*. Such loops can also easily be distributed
among many processors on parallel computers. We say that the *scalar code*
above, working on an element (a scalar) at a time, has been replaced by
an equivalent *vectorized code*. The process of vectorizing code is called
*vectorization*.

.. _wave:pde1:vec:fig1:

.. figure:: vectorized_diff.png
   :width: 400

   *Illustration of subtracting two slices of two arrays*


.. admonition:: Test your understanding

   Newcomers to vectorization are encouraged to choose
   a small array ``u``, say with five elements,
   and simulate with pen and paper
   both the loop version and the vectorized version above.




Finite difference schemes basically contain differences between array
elements with shifted indices. As an example,
consider the updating formula

.. code-block:: python

    for i in range(1, n-1):
        u2[i] = u[i-1] - 2*u[i] + u[i+1]

The vectorization consists of replacing the loop by arithmetics on
slices of arrays of length ``n-2``:

.. code-block:: python

    u2 = u[:-2] - 2*u[1:-1] + u[2:]
    u2 = u[0:n-2] - 2*u[1:n-1] + u[2:n]   # alternative

Note that the length of ``u2`` becomes ``n-2``. If ``u2`` is already an array of
length ``n`` and we want to use the formula to update all the "inner"
elements of ``u2``, as we will when solving a 1D wave equation, we can write

.. code-block:: python

    u2[1:-1]  = u[:-2] - 2*u[1:-1] + u[2:]
    u2[1:n-1] = u[0:n-2] - 2*u[1:n-1] + u[2:n]   # alternative

The first expression's right-hand side is realized by the
following steps, involving temporary arrays with intermediate results,
since each array operation can only involve one or two arrays.
The ``numpy`` package performs (behind the scenes) the first line above in
four steps:

.. code-block:: text

    temp1 = 2*u[1:-1]
    temp2 = u[:-2] - temp1
    temp3 = temp2 + u[2:]
    u2[1:-1] = temp3

We need three temporary arrays, but a user does not need to worry about
such temporary arrays.


.. admonition:: Common mistakes with array slices

   Array expressions with slices demand that the slices have the same
   shape. It easy to make a mistake in, e.g.,
   
   .. code-block:: python
   
       u2[1:n-1] = u[0:n-2] - 2*u[1:n-1] + u[2:n]
   
   and write
   
   .. code-block:: python
   
       u2[1:n-1] = u[0:n-2] - 2*u[1:n-1] + u[1:n]
   
   Now ``u[1:n]`` has wrong length (``n-1``) compared to the other array
   slices, causing a ``ValueError`` and the message
   ``could not broadcast input array from shape 103 into shape 104``
   (if ``n`` is 105). When such errors occur one must closely examine
   all the slices. Usually, it is easier to get upper limits of slices
   right when they use ``-1`` or ``-2`` or empty limit rather than
   expressions involving the length.
   
   Another common mistake is to forget the slice in the array on the
   left-hand side,
   
   .. code-block:: python
   
       u2 = u[0:n-2] - 2*u[1:n-1] + u[1:n]
   
   This is really crucial: now ``u2`` becomes a *new* array of length
   ``n-2``, which is the wrong length as we have no entries for the boundary
   values. We meant to insert the right-hand side array *into* the
   original ``u2`` array for the entries that correspond to the
   internal points in the mesh (``1:n-1`` or ``1:-1``).




Vectorization may also work nicely with functions. To illustrate, we may
extend the previous example as follows:

.. code-block:: python

    def f(x):
        return x**2 + 1
    
    for i in range(1, n-1):
        u2[i] = u[i-1] - 2*u[i] + u[i+1] + f(x[i])

Assuming ``u2``, ``u``, and ``x`` all have length ``n``, the vectorized
version becomes

.. code-block:: python

    u2[1:-1] = u[:-2] - 2*u[1:-1] + u[2:] + f(x[1:-1])

Obviously, ``f`` must be able to take an array as argument for ``f(x[1:-1])``
to make sense.

.. _wave:pde1:impl:vec:slices:fdm:

Finite difference schemes expressed as slices
---------------------------------------------

We now have the necessary tools to vectorize the wave equation
algorithm as described mathematically in the section :ref:`wave:string:alg`
and through code in the section :ref:`wave:pde1:impl:solver`.  There are
three loops: one for the initial condition, one for the first time
step, and finally the loop that is repeated for all subsequent time
levels. Since only the latter is repeated a potentially large number
of times, we limit our vectorization efforts to this loop:

.. code-block:: python

    for i in range(1, Nx):
        u[i] = 2*u_n[i] - u_nm1[i] + \ 
               C2*(u_n[i-1] - 2*u_n[i] + u_n[i+1])

The vectorized version becomes

.. code-block:: python

    u[1:-1] = - u_nm1[1:-1] + 2*u_n[1:-1] + \ 
              C2*(u_n[:-2] - 2*u_n[1:-1] + u_n[2:])

or

.. code-block:: python

    u[1:Nx] = 2*u_n[1:Nx]- u_nm1[1:Nx] + \ 
              C2*(u_n[0:Nx-1] - 2*u_n[1:Nx] + u_n[2:Nx+1])

.. We may vectorize the other loops regarding the initial condition and

.. the first time step, but the effect will hardly be

.. noticeable in long time simulations.

The program
`wave1D_u0v.py <http://tinyurl.com/nu656p2/wave/wave1D/wave1D_u0v.py>`__
contains a new version of the function ``solver`` where both the scalar
and the vectorized loops are included (the argument ``version`` is
set to ``scalar`` or ``vectorized``, respectively).

.. _wave:pde1:impl:vec:verify:quadratic:

Verification          (5)
-------------------------

.. index:: lambda function (Python)

We may reuse the quadratic solution :math:`{u_{\small\mbox{e}}}(x,t)=x(L-x)(1+{\frac{1}{2}}t)` for
verifying also the vectorized code. A test function can now verify
both the scalar and the vectorized version. Moreover, we may
use a ``user_action`` function that compares the computed and exact
solution at each time level and performs a test:

.. code-block:: python

    def test_quadratic():
        """
        Check the scalar and vectorized versions for
        a quadratic u(x,t)=x(L-x)(1+t/2) that is exactly reproduced.
        """
        # The following function must work for x as array or scalar
        u_exact = lambda x, t: x*(L - x)*(1 + 0.5*t)
        I = lambda x: u_exact(x, 0)
        V = lambda x: 0.5*u_exact(x, 0)
        # f is a scalar (zeros_like(x) works for scalar x too)
        f = lambda x, t: np.zeros_like(x) + 2*c**2*(1 + 0.5*t)
    
        L = 2.5
        c = 1.5
        C = 0.75
        Nx = 3  # Very coarse mesh for this exact test
        dt = C*(L/Nx)/c
        T = 18
    
        def assert_no_error(u, x, t, n):
            u_e = u_exact(x, t[n])
            tol = 1E-13
            diff = np.abs(u - u_e).max()
            assert diff < tol
    
        solver(I, V, f, c, L, dt, C, T,
               user_action=assert_no_error, version='scalar')
        solver(I, V, f, c, L, dt, C, T,
               user_action=assert_no_error, version='vectorized')


.. admonition:: Lambda functions

   The code segment above demonstrates how to achieve very
   compact code, without degraded readability,
   by use of lambda functions for the various
   input parameters that require a Python function. In essence,
   
   .. code-block:: python
   
       f = lambda x, t: L*(x-t)**2
   
   is equivalent to
   
   .. code-block:: python
   
       def f(x, t):
           return L(x-t)**2
   
   Note that lambda functions can just contain a single expression and no
   statements.
   
   One advantage with lambda functions is that they can be used directly
   in calls:
   
   .. code-block:: python
   
       solver(I=lambda x: sin(pi*x/L), V=0, f=0, ...)




Efficiency measurements
-----------------------

The ``wave1D_u0v.py`` contains our new ``solver`` function with both
scalar and vectorized code. For comparing the efficiency
of scalar versus vectorized code, we need a ``viz`` function
as discussed in the section :ref:`wave:pde1:impl:animate`.
All of this ``viz`` function can be reused, except the call
to ``solver_function``. This call lacks the parameter
``version``, which we want to set to ``vectorized`` and ``scalar``
for our efficiency measurements.

One solution is to copy the ``viz`` code from ``wave1D_u0`` into
``wave1D_u0v.py`` and add a ``version`` argument to the ``solver_function`` call.
Taking into account how much animation code we
then duplicate, this is not a good idea.
Alternatively,
introducing the ``version`` argument in ``wave1D_u0.viz``, so that this function
can be imported into ``wave1D_u0v.py``, is not
a good solution either, since ``version`` has no meaning in that file.
We need better ideas!

Solution 1
~~~~~~~~~~

Calling ``viz`` in ``wave1D_u0`` with ``solver_function`` as our new
solver in ``wave1D_u0v`` works fine, since this solver has
``version='vectorized'`` as default value. The problem arises when we
want to test ``version='scalar'``. The simplest solution is then
to use ``wave1D_u0.solver`` instead. We make a new ``viz`` function
in ``wave1D_u0v.py`` that has a ``version`` argument and that just
calls ``wave1D_u0.viz``:

.. code-block:: python

    def viz(
        I, V, f, c, L, dt, C, T,  # PDE parameters
        umin, umax,               # Interval for u in plots
        animate=True,             # Simulation with animation?
        tool='matplotlib',        # 'matplotlib' or 'scitools'
        solver_function=solver,   # Function with numerical algorithm
        version='vectorized',     # 'scalar' or 'vectorized'
        ):
        import wave1D_u0
        if version == 'vectorized':
            # Reuse viz from wave1D_u0, but with the present
            # modules' new vectorized solver (which has
            # version='vectorized' as default argument;
            # wave1D_u0.viz does not feature this argument)
            cpu = wave1D_u0.viz(
                I, V, f, c, L, dt, C, T, umin, umax,
                animate, tool, solver_function=solver)
        elif version == 'scalar':
            # Call wave1D_u0.viz with a solver with
            # scalar code and use wave1D_u0.solver.
            cpu = wave1D_u0.viz(
                I, V, f, c, L, dt, C, T, umin, umax,
                animate, tool,
                solver_function=wave1D_u0.solver)

Solution 2
~~~~~~~~~~

There is a more advanced and fancier solution featuring a very useful trick:
we can make a new function that will always call ``wave1D_u0v.solver``
with ``version='scalar'``. The ``functools.partial`` function from
standard Python takes a function ``func`` as argument and
a series of positional and keyword arguments and returns a
new function that will call ``func`` with the supplied arguments,
while the user can control all the other arguments in ``func``.
Consider a trivial example,

.. code-block:: python

    def f(a, b, c=2):
        return a + b + c

We want to ensure that ``f`` is always called with ``c=3``, i.e., ``f``
has only two "free" arguments ``a`` and ``b``.
This functionality is obtained by

.. code-block:: python

    import functools
    f2 = functools.partial(f, c=3)
    
    print f2(1, 2)  # results in 1+2+3=6

Now ``f2`` calls ``f`` with whatever the user supplies as ``a`` and ``b``,
but ``c`` is always ``3``.

Back to our ``viz`` code, we can do

.. code-block:: python

    import functools
    # Call wave1D_u0.solver with version fixed to scalar
    scalar_solver = functools.partial(wave1D_u0.solver, version='scalar')
    cpu = wave1D_u0.viz(
            I, V, f, c, L, dt, C, T, umin, umax,
            animate, tool, solver_function=scalar_solver)

The new ``scalar_solver`` takes the same arguments as
``wave1D_u0.scalar`` and calls ``wave1D_u0v.scalar``,
but always supplies the extra argument
``version='scalar'``. When sending this ``solver_function``
to ``wave1D_u0.viz``, the latter will call ``wave1D_u0v.solver``
with all the ``I``, ``V``, ``f``, etc., arguments we supply, plus
``version='scalar'``.

Efficiency experiments
~~~~~~~~~~~~~~~~~~~~~~

We now have a ``viz`` function that can call our solver function both in
scalar and vectorized mode. The function ``run_efficiency_experiments``
in ``wave1D_u0v.py`` performs a set of experiments and reports the
CPU time spent in the scalar and vectorized solver for
the previous string vibration example with spatial mesh resolutions
:math:`N_x=50,100,200,400,800`. Running this function reveals
that the vectorized
code runs substantially faster: the vectorized code runs approximately
:math:`N_x/10` times as fast as the scalar code!

.. _wave:pde1:impl:ref:switch:

Remark on the updating of arrays
--------------------------------

At the end of each time step we need to update the ``u_nm1`` and ``u_n``
arrays such that they have the right content for the next time step:

.. code-block:: python

    u_nm1[:] = u_n
    u_n[:] = u

The order here is important: updating ``u_n`` first, makes ``u_nm1`` equal
to ``u``, which is wrong!

The assignment ``u_n[:] = u`` copies the content of the ``u`` array into
the elements of the ``u_n`` array. Such copying takes time, but
that time is negligible compared to the time needed for
computing ``u`` from the finite difference formula,
even when the formula has a vectorized implementation.
However, efficiency of program code is a key topic when solving
PDEs numerically (particularly when there are two or three
space dimensions), so it must be mentioned that there exists a
much more efficient way of making the arrays ``u_nm1`` and ``u_n``
ready for the next time step. The idea is based on *switching
references* and explained as follows.

A Python variable is actually a reference to some object (C programmers
may think of pointers). Instead of copying data, we can let ``u_nm1``
refer to the ``u_n`` object and ``u_n`` refer to the ``u`` object.
This is a very efficient operation (like switching pointers in C).
A naive implementation like

.. code-block:: python

    u_nm1 = u_n
    u_n = u

will fail, however, because now ``u_nm1`` refers to the ``u_n`` object,
but then the name ``u_n`` refers to ``u``, so that this ``u`` object
has two references, ``u_n`` and ``u``, while our third array, originally
referred to by ``u_nm1``, has no more references and is lost.
This means that the variables ``u``, ``u_n``, and ``u_nm1`` refer to two
arrays and not three. Consequently, the computations at the next
time level will be messed up since updating the elements in
``u`` will imply updating the elements in ``u_n`` too so the solution
at the previous time step, which is crucial in our formulas, is
destroyed.

While ``u_nm1 = u_n`` is fine, ``u_n = u`` is problematic, so
the solution to this problem is to ensure that ``u``
points to the ``u_nm1`` array. This is mathematically wrong, but
new correct values will be filled into ``u`` at the next time step
and make it right.

The correct switch of references is

.. code-block:: python

    tmp = u_nm1
    u_nm1 = u_n
    u_n = u
    u = tmp

We can get rid of the temporary reference ``tmp`` by writing

.. code-block:: python

    u_nm1, u_n, u = u_n, u, u_nm1

This switching of references for updating our arrays
will be used in later implementations.


.. admonition:: Caution

   The update ``u_nm1, u_n, u = u_n, u, u_nm1`` leaves wrong content in ``u``
   at the final time step. This means that if we return ``u``, as we
   do in the example codes here, we actually return ``u_nm1``, which is
   obviously wrong. It is therefore important to adjust the content
   of ``u`` to ``u = u_n`` before returning ``u``. (Note that
   the ``user_action`` function
   reduces the need to return the solution from the solver.)




Exercises          (2)
======================

.. --- begin exercise ---

.. _wave:exer:standingwave:

Exercise 2.1: Simulate a standing wave
--------------------------------------

The purpose of this exercise is to simulate standing waves on :math:`[0,L]`
and illustrate the error in the simulation.
Standing waves arise from an initial condition

.. math::
         u(x,0)= A \sin\left(\frac{\pi}{L}mx\right),

where :math:`m` is an integer and :math:`A` is a freely chosen amplitude.
The corresponding exact solution can be computed and reads

.. math::
         {u_{\small\mbox{e}}}(x,t) =  A\sin\left(\frac{\pi}{L}mx\right)
        \cos\left(\frac{\pi}{L}mct\right){\thinspace .}
        

**a)**
Explain that for a function :math:`\sin kx\cos \omega t` the wave length
in space is :math:`\lambda = 2\pi /k` and the period in time is :math:`P=2\pi/\omega`.
Use these expressions to find the wave length in space and period in
time of :math:`{u_{\small\mbox{e}}}` above.

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

**b)**
Import the ``solver`` function from ``wave1D_u0.py`` into a new file
where the ``viz`` function is reimplemented such that it
plots either the numerical *and* the exact solution, *or* the error.

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

**c)**
Make animations where you illustrate how the error
:math:`e^n_i ={u_{\small\mbox{e}}}(x_i, t_n)- u^n_i`
develops and increases in time. Also make animations of
:math:`u` and :math:`{u_{\small\mbox{e}}}` simultaneously.

.. --- begin hint in exercise ---

**Hint 1.**
Quite long time simulations are needed in order to display significant
discrepancies between the numerical and exact solution.

.. --- end hint in exercise ---

.. --- begin hint in exercise ---

**Hint 2.**
A possible set of parameters is :math:`L=12`, :math:`m=9`, :math:`c=2`, :math:`A=1`, :math:`N_x=80`,
:math:`C=0.8`. The error mesh function :math:`e^n` can be simulated for 10 periods,
while 20-30 periods are needed to show significant differences between
the curves for the numerical and exact solution.

.. --- end hint in exercise ---

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

Filename: ``wave_standing``.

.. Closing remarks for this Exercise

Remarks          (3)
~~~~~~~~~~~~~~~~~~~~

The important
parameters for numerical quality are :math:`C` and :math:`k\Delta x`, where
:math:`C=c\Delta t/\Delta x` is the Courant number and :math:`k` is defined above
(:math:`k\Delta x` is proportional to how many mesh points we have per wave length
in space, see the section :ref:`wave:pde1:num:dispersion` for explanation).

.. --- end exercise ---

.. --- begin exercise ---

.. _wave:exer:store:list:

Exercise 2.2: Add storage of solution in a user action function
---------------------------------------------------------------

Extend the ``plot_u`` function in the file ``wave1D_u0.py`` to also store
the solutions ``u`` in a list.
To this end, declare ``all_u`` as
an empty list in the ``viz`` function, outside ``plot_u``, and perform
an append operation inside the ``plot_u`` function. Note that a
function, like ``plot_u``, inside another function, like ``viz``,
remembers all local variables in ``viz`` function, including ``all_u``,
even when ``plot_u`` is called (as ``user_action``) in the ``solver`` function.
Test both ``all_u.append(u)`` and ``all_u.append(u.copy())``.
Why does one of these constructions fail to store the solution correctly?
Let the ``viz`` function return the ``all_u`` list
converted to a two-dimensional ``numpy`` array.

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

Filename: ``wave1D_u0_s_store``.

.. --- end exercise ---

.. --- begin exercise ---

.. _wave:exer:store:list:class:

Exercise 2.3: Use a class for the user action function
------------------------------------------------------

Redo :ref:`wave:exer:store:list` using a class for the user
action function. Let the ``all_u`` list be an attribute in this class
and implement the user action function as a method (the special method
``__call__`` is a natural choice). The class versions avoid that the
user action function depends on parameters defined outside the
function (such as ``all_u`` in :ref:`wave:exer:store:list`).

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

Filename: ``wave1D_u0_s2c``.

.. --- end exercise ---

.. --- begin exercise ---

.. _wave:exer:multiple:C:

Exercise 2.4: Compare several Courant numbers in one movie
----------------------------------------------------------

The goal of this exercise is to make movies where several curves,
corresponding to different Courant numbers, are visualized. Write a
program that resembles ``wave1D_u0_s2c.py`` in :ref:`wave:exer:store:list:class`, but with a ``viz`` function that
can take a list of ``C`` values as argument and create a movie with
solutions corresponding to the given ``C`` values. The ``plot_u`` function
must be changed to store the solution in an array (see :ref:`wave:exer:store:list` or :ref:`wave:exer:store:list:class` for
details), ``solver`` must be computed for each value of the Courant
number, and finally one must run through each time step and plot all
the spatial solution curves in one figure and store it in a file.

The challenge in such a visualization is to ensure that the curves in
one plot correspond to the same time point. The easiest remedy is to
keep the time resolution constant and change the space resolution
to change the Courant number. Note that each spatial grid is needed for
the final plotting, so it is an option to store those grids too.

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

Filename: ``wave_numerics_comparison``.

.. --- end exercise ---

.. --- begin exercise ---

.. _wave:exer:useraction:generator:

Exercise 2.5: Implementing the solver function as a generator
-------------------------------------------------------------

The callback function ``user_action(u, x, t, n)`` is called from the
``solver`` function (in, e.g., ``wave1D_u0.py``) at every time level and lets
the user work perform desired actions with the solution, like plotting it
on the screen. We have implemented the callback function in the typical
way it would have been done in C and Fortran. Specifically, the code looks
like

.. code-block:: python

    if user_action is not None:
        if user_action(u, x, t, n):
            break

Many Python programmers, however, may claim that ``solver`` is an iterative
process, and that iterative processes with callbacks to the user code is
more elegantly implemented as *generators*. The rest of the text has little
meaning unless you are familiar with Python generators and the ``yield``
statement.

Instead of calling ``user_action``, the ``solver`` function
issues a ``yield`` statement, which is a kind of ``return`` statement:

.. code-block:: python

    yield u, x, t, n

The program control is directed back to the calling code:

.. code-block:: python

    for u, x, t, n in solver(...):
        # Do something with u at t[n]

When the block is done, ``solver`` continues with the statement after ``yield``.
Note that the functionality of terminating the solution process if
``user_action`` returns a ``True`` value is not possible to implement in the
generator case.

Implement the ``solver`` function as a generator, and plot the solution
at each time step.
Filename: ``wave1D_u0_generator``.

.. --- end exercise ---

.. --- begin exercise ---

.. _wave:exer:mesh1D:calculus:

Project 2.6: Calculus with 1D mesh functions
--------------------------------------------

This project explores integration and differentiation of
mesh functions, both with scalar and vectorized implementations.
We are given a mesh function :math:`f_i` on a spatial one-dimensional
mesh :math:`x_i=i\Delta x`, :math:`i=0,\ldots,N_x`, over the interval :math:`[a,b]`.

**a)**
Define the discrete derivative of :math:`f_i` by using centered
differences at internal mesh points and one-sided differences
at the end points. Implement a scalar version of
the computation in a Python function and write an associated unit test
for the linear case :math:`f(x)=4x-2.5` where the discrete derivative should
be exact.

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

**b)**
Vectorize the implementation of the discrete derivative.
Extend the unit test to check the validity of the implementation.

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

**c)**
To compute the discrete integral :math:`F_i` of :math:`f_i`, we assume that
the mesh function :math:`f_i` varies linearly between the mesh points.
Let :math:`f(x)` be such a linear interpolant of :math:`f_i`. We then
have

.. math::
         F_i = \int_{x_0}^{x_i} f(x) dx{\thinspace .}

The exact integral of a piecewise linear function :math:`f(x)` is
given by the Trapezoidal rule. Show
that if :math:`F_{i}` is already computed, we can find :math:`F_{i+1}`
from

.. math::
         F_{i+1} = F_i + \frac{1}{2}(f_i + f_{i+1})\Delta x{\thinspace .}

Make a function for the scalar implementation of the discrete integral
as a mesh function. That is, the function should return
:math:`F_i` for :math:`i=0,\ldots,N_x`.
For a unit test one can use the fact that the above defined
discrete integral of a linear
function (say :math:`f(x)=4x-2.5`) is exact.

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

**d)**
Vectorize the implementation of the discrete integral.
Extend the unit test to check the validity of the implementation.

.. --- begin hint in exercise ---

**Hint.**
Interpret the recursive formula for :math:`F_{i+1}` as a sum.
Make an array with each element of the sum and use the "cumsum"
(``numpy.cumsum``) operation to compute the accumulative sum:
``numpy.cumsum([1,3,5])`` is ``[1,4,9]``.

.. --- end hint in exercise ---

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

**e)**
Create a class ``MeshCalculus`` that can integrate and differentiate
mesh functions. The class can just define some methods that call
the previously implemented Python functions. Here is an example
on the usage:

.. code-block:: python

    import numpy as np
    calc = MeshCalculus(vectorized=True)
    x = np.linspace(0, 1, 11)        # mesh
    f = np.exp(x)                    # mesh function
    df = calc.differentiate(f, x)    # discrete derivative
    F = calc.integrate(f, x)         # discrete anti-derivative

.. removed !bsol ... !esol environment (because of the command-line option --without_solutions)

.. --- begin solution of exercise ---

**Solution.**
The final version of the code reads

.. code-block:: python

    # -*- coding: utf-8 -*-
    """
    Calculus with a 1D mesh function.
    """
    import numpy as np
    
    class MeshCalculus:
        def __init__(self, vectorized=True):
            self.vectorized = vectorized
    
        def differentiate(self, f, x):
            '''
            Computes the derivative of f by centered differences, but 
            forw and back difference at the start and end, respectively.
            '''
            dx = x[1] - x[0]
            Nx = len(x) - 1     # number of spatial steps
            num_dfdx = np.zeros(Nx+1)
            # Compute approximate derivatives at end-points first
            num_dfdx[0] = (f(x[1]) - f(x[0]))/dx          # FD approx.
            num_dfdx[Nx] = (f(x[Nx]) - f(x[Nx-1]))/dx     # BD approx.
            # proceed with approximate derivatives for inner mesh points
            if self.vectorized:
                num_dfdx[1:-1] = (f(x[2:]) - f(x[:-2]))/(2*dx)
            else:   # scalar version
                for i in range(1, Nx):
                    num_dfdx[i] = (f(x[i+1]) - f(x[i-1]))/(2*dx)
            return num_dfdx
        
        def integrate(self, f, x):
            '''
            Computes the integral of f(x) over the interval 
            covered by x. 
            '''
            dx = x[1] - x[0]
            F = np.zeros(len(x))   
            F[0] = 0    # starting value for iterative scheme
            if self.vectorized:
                all_trapezoids = np.zeros(len(x)-1)    
                all_trapezoids[:] = 0.5*(f(x[:-1]) + f(x[1:]))*dx   
                F[1:] = np.cumsum(all_trapezoids)
            else:   # scalar version
                for i in range(0, len(x)-1):
                    F[i+1] = F[i] + 0.5*(f(x[i]) + f(x[i+1]))*dx    
            return F
        
    def test_differentiate():
        def f(x):
            return 4*x - 2.5
        def dfdx(x):
            derivatives = np.zeros(len(x))
            derivatives[:] = 4
            return derivatives
            
        a = 0; b = 1; Nx = 10
        x = np.linspace(a, b, Nx+1)    
        exact_dfdx = dfdx(x)        # compute exact derivatives
        # test vectorized version
        calc_v = MeshCalculus(vectorized=True)
        num_dfdx  = calc_v.differentiate(f, x)
        print np.abs(num_dfdx - exact_dfdx)
        diff = np.abs(num_dfdx - exact_dfdx).max()
        tol = 1E-14
        assert diff < tol
        # test scalar version
        calc = MeshCalculus(vectorized=False)
        num_dfdx  = calc.differentiate(f, x)
        print np.abs(num_dfdx - exact_dfdx)
        diff = np.abs(num_dfdx - exact_dfdx).max()
        assert diff < tol
        
    def test_integrate():
        def f(x):
            return 4*x - 2.5
        a = 0; b = 1; Nx = 10
    #    a = 2.5/4; b = 10; Nx = 2
        x = np.linspace(a, b, Nx+1)    
        # The exact integral amounts to the total area of two triangles
        I_exact = 0.5*abs(2.5/4 - a)*f(a) + 0.5*abs(b - 2.5/4)*f(b)
        # test vectorized version    
        calc_v = MeshCalculus(vectorized=True)    
        F = calc_v.integrate(f, x)
        print F, I_exact
        diff = np.abs(F[-1] - I_exact)
        print diff
        tol = 1E-14
        assert diff < tol    
        # test scalar version
        calc = MeshCalculus(vectorized=False)        
        F = calc.integrate(f, x)
        print F, I_exact
        diff = np.abs(F[-1] - I_exact)
        print diff
        assert diff < tol
        
        
    if __name__ == '__main__':
        test_differentiate()
        test_integrate()

.. --- end solution of exercise ---

Filename: ``mesh_calculus_1D``.

.. --- end exercise ---

